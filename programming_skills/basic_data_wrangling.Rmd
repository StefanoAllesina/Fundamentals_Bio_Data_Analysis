---
title: "Basic data wrangling"
author: "Dmitry Kondrashov & Stefano Allesina"
date: "Fundamentals of Biological Data Analysis -- BIOS 26318"
output:
  html_document:
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
urlcolor: blue
---

```{r knitr, echo=FALSE}
knitr::opts_chunk$set(
  eval      = TRUE,
  comment   = "#",
  results   = "hold",
  # collapse  = TRUE,
  fig.align = "center")
```

# Goal
Learn how to manipulate large data sets by writing efficient, consistent, and compact code. Introduce the use of `dplyr`, `tidyr`, and the "pipeline" operator `%>%`. Effortlessly produce statistics for grouped data. Massage data into tidy form.

# What is data wrangling?
As biologists living in the XXI century, we are often faced with tons of data, possibly replicated over several organisms, treatments, or locations. We would like to streamline and automate our analysis as much as possible, writing scripts that are easy to read, fast to run, and easy to debug. Base `R` can get the job done, but often the code contains complicated operations, and a lot of `$` signs and brackets.

We're going to learn about the packages `dplyr` and `tidyr`, which are part of `tidyverse` and can be used to manipulate large data frames in a simple and straightforward way. These tools are also much faster than the corresponding base `R` commands, are very compact, and can be concatenated into "pipelines". 

To start, we need to import the libraries:
```{r, message=FALSE}
library(tidyverse) # this loads them both, along with other packages
```

Then, we need a dataset to play with. We take a simple dataset from:

> Lippens C, Faivre B, Lechenault C, Sorci G (2017) [Aging parasites produce offspring with poor fitness prospects](https://doi.org/10.1098/rsbl.2016.0888). Biology Letters 13(2): 20160888. 

The Authors have found that senescing parasites produce offspring with lower survival probability and lower fertility. To produce this result, they have infected mice with the parasite nematode *Heligmosomoides polygyrus*. They collected the eggs found in the faeces at different times, corresponding to the age of the worm (in days). Then they used the hatched larvae to infect mice, and counted the eggs shedded by the newly infected mice for 28 days. At that point, mice were sacrificed and adult worms in the intestine counted.

```{r}
# to read Excel files
source("../general_code/read_xls_from_url.R")
# original URL:
# https://datadryad.org/bitstream/handle/10255/dryad.135877/dryad_data.xlsx
dt <- read_xlsx_from_url("https://tinyurl.com/yclwadb8") 
```

# A new data type, `tibble`

This is now a :
```{r}
class(dt)
```

`dplyr` ships with a new data type, called a `tibble`. To convert from data frame, use
```{r, eval=FALSE}
# load a data frame
data("trees")
class(trees)
trees <- as_tibble(trees)
class(trees)
```

The nice feature of `tbl` objects is that they will print only what fits on the screen, and also give you useful information on the size of the data, as well as the type of data  in each column. Other than that, a `tbl` object behaves very much like a `data.frame`. In some rare cases, you want to transform the `tbl` back into a `data.frame`. For this, use the function `as.data.frame(tbl_object)`.

We can take a look at the data using one of several functions:

* `head(dt)` shows the first few rows
* `tail(dt)` shows the last few rows
* `glimpse(dt)` a summary of the data (similar to `str` in base R)
* `View(dt)` open in spreadsheet-like window

# Selecting rows and columns
There are many ways to subset the data, either by row (subsetting the *observations*), or by column (subsetting the *variables*). For example, suppose we want to count how many rows contain data for `time post-infection` 28. When reading data using `tidyverse`, the column names are not altered (contrary to what happens using `read.csv`). As such, they might be difficult to type. No problem: simply enclose the names with "back tickmarks" "`":

```{r}
filter(dt, `time post-infection` == 28)
```

We have 20 observations. We have used the command `filter(tbl, conditions)` to select certain observations. We can combine several conditions, by listing them side by side, possibly using logical operators.

> **Exercise:** what does this do?
```{r}
filter(dt, `Parental age` > 20, 
           `number of adult worms` > 20, 
           `fecal egg count` < 10)
```

We can also select particular variables (columns) using the function `select(tbl, cols to select)`. For example, select `id` and `number of adult worms`:
```{r}
select(dt, id, `number of adult worms`)
```

How many `id`s are represented in the data set? We can use the function `distinct(tbl, cols to sellect)` to retain only the rows that differ from each other:

```{r}
distinct(select(dt, id))
```

Showing that there are 20 replicates, once we removed the duplicates. 

Other ways to subset observations:

- `sample_n(tbl, howmany, replace = TRUE)` sample `howmany` rows at random with replacement
- `sample_frac(tbl, proportion, replace = FALSE)` sample a certain proportion (e.g. `0.2` for 20%) of rows at random without replacement
- `slice(tbl, 5:20)` extract the rows `5` to `20`
- ``top_n(tbl, 10, `number of adult worms`)`` extract the first `10` rows, once ordered by `number of adult worms`

More ways to select columns:

- `select(dt, contains("time"))` select all columns containing the word `time`
- ``select(dt, -id, -`Parental age`)`` exclude the columns `id` and `Parental age`
- `select(dt, matches("count|time"))` select all columns whose names match a regular expression

# Creating pipelines using `%>%`
We've been calling nested functions, such as `distinct(select(dt, id))`. If you have to add another layer or two, the code would become unreadable. `dplyr` allows you to "un-nest" these functions and create a "pipeline", in which you concatenate commands separated by the special operator `%>%`. For example:

```{r}
dt %>% # take a data table
  select(id) %>% # select a column
  distinct() # remove duplicates
```

does exactly the same as the command above, but is much more readable. By concatenating many commands, you can create incredibly complex pipelines while retaining readability.

Another advantage of pipelines is that they help with name completion. In fact, `RStudio` is running in the background your pipeline while you type it. Try typing `dt %>% filter(` and then start typing `time` and press `Tab`: you will see the options to complete the column name; choose it with your arrows and hit `Return`. The back tickmarks will be added automatically.

# Producing summaries
Sometimes we need to calculate statistics on certain columns. For example, calculate the average number of eggs shedded by the infected mice. We can do this using `summarize`:
```{r}
dt %>% summarize(avg = mean(`fecal egg count`, na.rm = TRUE))
```

where we used `na.rm = TRUE` to ignore missing values. This command returns a `tbl` object with just the average egg count. You can combine multiple statistics (use `first`, `last`, `min`, `max`, `n` [count the number of rows], `n_distinct` [count the number of distinct rows], `mean`, `median`, `var`, `sd`, etc.):

```{r}
dt %>% summarize(avg = mean(`fecal egg count`, na.rm = TRUE), 
                 sd = sd(`fecal egg count`, na.rm = TRUE), 
                 median = median(`fecal egg count`, na.rm = TRUE))
```

# Summaries by group
One of the most useful features of `dplyr` is the ability to produce statistics for the data once subsetted by *groups*. For example, we would like to measure whether older worms produce less virulent offspring. We can then group the data by `Parental age`, and calculate the mean `fecal egg count` once the data are split into groups:

```{r}
dt %>% group_by(`Parental age`) %>% summarize(mean = mean(`fecal egg count`, na.rm = TRUE))
```

showing that younger worms produce highly virulent offspring.

> **Exercise:** find the average `number of adult worms` by `Parental age`. Filter the data to consider only 28 days for `time post-infection`.   

# Ordering the data 
To order the data according to one or more variables, use `arrange()`:
```{r}
dt %>% arrange(`number of adult worms`)
dt %>% arrange(desc(`number of adult worms`))
```

# Renaming columns
To rename one or more columns, use `rename()`:
```{r}
dt %>% rename(pa = `Parental age`)
```

# Adding new variables using mutate
If you want to add one or more new columns, with the content being a function of other columns, use the function `mutate`:

```{r}
#HERE
```

use the function `transmute()` to create a new column and drop the original columns. You can also use `mutate` and `transmute` on grouped data:

```{r, eval=FALSE}
```

